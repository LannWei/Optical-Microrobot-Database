<html lang="en">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <title>Optical Microrobot</title>
    <link rel="stylesheet" type="text/css" href="./static/css/index.css">
    <!-- <link rel="shortcut icon" href="/static/favicon.ico">
    <link rel="icon" href="/static/favicon.png" type="image/png"> -->
</head>

<body>
    <div id="wrap">
        <!-- Header 区域 -->
        <header class="header">
            <!-- 左侧 Logo 图片 -->
            <img src="./static/logo.png" alt="Logo" class="logo">

            <!-- 右侧导航链接 -->
            <nav class="nav-links">
                <a href="#intro">Intro</a>
                <a href="#download">Download</a>
                <a href="#publications">Publications</a>
                <a href="#about">About</a>
            </nav>
        </header>

        <!-- Introduction Section -->
        <div id="intro">
            <div class="main">
                <h3>Introduction</h3>
                <p>
                    Optical microrobots are widely employed in biomedical research,
                    offering valuable insights for both in vitro and in vivo applications.
                    Precise depth estimation is essential for accurate 3D reconstruction and
                    autofocus capabilities in microrobotic platforms. Additionally, both pose
                    and depth estimations enhance the 3D perception required for
                    microrobots to perform complex tasks, such as dexterous
                    micromanipulation.
                </p>
                <figure id="fig1" class="image-container">
                    <img src="./resource/WebPage_image1.png" alt="Database Overview">
                    <figcaption class="image-caption">Fig. 1 Database Overview</figcaption>
                </figure>
                <p>
                    This dataset is organized into two main parts, as illustrated in Fig. <a href="#fig1">1</a>.
                    The first part is designed for the task of optical microrobot depth
                    prediction, treated as a regression problem. It includes 22 types of
                    optical microrobots, with each type comprising 314 frames in the
                    training set and 265 frames in the test set.
                </p>
                <p>
                    The second part of the dataset supports pose prediction, focusing on
                    pitch and roll angles. It includes six different types of microrobots with a
                    total of 129 distinct poses. For each pose, the training data contains
                    180 frames, while the test data includes 46 frames.
                </p>
                <figure id="fig2" class="image-container" style="width: 100%;">
                    <img src="./resource/WebPage_image2.png" alt="Optical Microrobot Visualization">
                    <figcaption class="image-caption">Fig. 2 Optical Microrobot Visualization</figcaption>
                </figure>
                <figure id="fig3" class="image-container" style="width: 100%;margin-top: 12px;">
                    <div class="image-group">
                        <!-- Gif on the left -->
                        <img src="./resource/test.gif" alt="Git" class="gif-image">
                
                        <!-- the SVG arrow -->
                        <svg class="arrow" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
                            <path d="M3 12h15m0 0l-5-5m5 5l-5 5" stroke="#333" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
                        </svg>
                
                        <!-- 6 images on the right -->
                        <div class="result-images">
                            <img src="./resource/16-Robot-Body-Ball-withLongSpring_OT_00001.jpg" alt="Image 1">
                            <img src="./resource/16-Robot-Body-Ball-withLongSpring_OT_00010.jpg" alt="Image 2">
                            <img src="./resource/16-Robot-Body-Ball-withLongSpring_OT_00016.jpg" alt="Image 3">
                            <img src="./resource/16-Robot-Body-Ball-withLongSpring_OT_00050.jpg" alt="Image 4">
                            <img src="./resource/16-Robot-Body-Ball-withLongSpring_OT_00066.jpg" alt="Image 5">
                            <img src="./resource/16-Robot-Body-Ball-withLongSpring_OT_00090.jpg" alt="Image 6">
                        </div>
                    </div>
                    <figcaption class="image-caption">Fig. 3 Process Optical Tweezer Video to Single Frames</figcaption>
                </figure>
                <p>
                    Fig. <a href="#fig2">2</a> presents CAD images of the various optical microrobots included
                    in this dataset, each labeled with its corresponding name for easy
                    identification. Fig. <a href="#fig3">3</a> provides an example video of microrobots recorded
                    using an optical tweezer. For user convenience, the dataset includes
                    pre-processed frames and labels. To access the original video files, please contact:
                    <a href="mailto:d.zhang17@imperial.ac.uk">d.zhang17@imperial.ac.uk</a> 
                    or <a href="mailto:l.wei24@imperial.ac.uk">l.wei24@imperial.ac.uk</a>.    
                </p>
            </div>
        </div>

        <!-- Download Section -->
        <div id="download">
            <div class="main">
                <h3>Download</h3>
                <div id="about_content" class="aboutoverview">
                    <p>The optical microrobot database is available at:</p>
                    <div style="text-align: center;">
                        <a href="https://store.google.com/collection/devices" class="google-device-link" target="_blank">
                            <img src="https://ssl.gstatic.com/images/branding/product/1x/drive_2020q4_48dp.png" alt="Google Device Logo" class="google-logo">
                            <span>Optical Microrobot Dataset</span>
                        </a>   
                    </div>      
                    <p>
                    If you encounter any issues accessing the files, please feel free to
                    contact us at <a href="mailto:d.zhang17@imperial.ac.uk">d.zhang17@imperial.ac.uk</a> or <a href="mailto:l.wei24@imperial.ac.uk">l.wei24@imperial.ac.uk</a>.
                    </p>
                    <p><strong>Citation:</strong> When using the datasets, please cite: xxx.</p>
                </div>
            </div>
        </div>

        <!-- Publications Section  -->
        <div id="publications">
            <div class="main">
                <h3>Publications</h3>
                <div id="about_content" class="aboutoverview">
                    <ol>
                        <li>Zhang, Dandan, Antoine Barbot, Florent Seichepine, Frank P-W. Lo,
                            Wenjia Bai, Guang-Zhong Yang, and Benny Lo. "<strong>Micro-object pose
                            estimation with sim-to-real transfer learning using small
                            database.</strong>" Communications Physics 5, no. 1 (2022): 80.</li>
                        <li>Zhang, Dandan, Yunxiao Ren, Antoine Barbot, Florent Seichepine,
                            Benny Lo, Zhuo-Chen Ma, and Guang-Zhong Yang. "<strong>Fabrication and
                            optical manipulation of micro-robots for biomedical
                            applications.</strong>" Matter 5, no. 10 (2022): 3135-3160.</li>
                        <li>Zhang, Dandan, Antoine Barbot, Florent Seichepine, Frank P-W. Lo,
                            Wenjia Bai, Guang-Zhong Yang, and Benny Lo. "<strong>Micro-object pose
                            estimation with sim-to-real transfer learning using small
                            dataset.</strong>" Communications Physics 5, no. 1 (2022): 80.</li>
                        <li>Ren, Yunxiao, Meysam Keshavarz, Salzitsa Anastasova, Ghazal
                            Hatami, Benny Lo, and Dandan Zhang. "<strong>Machine learning-based realtime
                            localization and automatic trapping of multiple microrobots in
                            optical tweezer.</strong>" In 2022 international conference on manipulation,
                            automation and robotics at small scales (MARSS), pp. 1-6. IEEE, 2022.</li>
                        <li>Zhang, Dandan, Frank P-W. Lo, Jian-Qing Zheng, Wenjia Bai, Guang-
                            Zhong Yang, and Benny Lo. "<strong>Data-driven microscopic pose and
                            depth estimation for optical microrobot manipulation.</strong>" Acs
                            Photonics 7, no. 11 (2020): 3003-3014.</li>
                        <li>Zhang, Dandan, Antoine Barbot, Benny Lo, and Guang‐Zhong Yang.
                            "<strong>Distributed force control for microrobot manipulation via planar
                            multi‐spot optical tweezer.</strong>" Advanced Optical Materials 8, no. 21
                            (2020): 2000543</li>
                    </ol>
                </div>
            </div>
        </div>

        <!-- About Section  -->
        <div id="about">
            <div class="main">
                <h3>About</h3>
                <div id="about_content" class="aboutoverview">
                    <div class="subtitle">How can the microtobot be fabricated?</div>
                    The fabrication of optical microrobots was accomplished using a
                    Nanoscribe 3D printer (Nanoscribe GmbH, Germany), with IP-L 780
                    photoresist selected as the material. This biocompatible, dielectric
                    photoresist has a refractive index of 1.52, providing a beneficial contrast
                    with the surrounding medium (water, with a refractive index of 1.33).
                    The manufacturing process utilized two-photon polymerization (2PP),
                    achieving a resolution of 100 nm through the Nanoscribe 3D printing
                    system. Microplatforms and microrobots used in experimental
                    validations were printed directly onto a glass substrate and subsequently
                    placed in deionized (DI) water within a spacer for testing.
                    <br><br>
                    <div class="subtitle">How is the video/image collected?</div>
                    The microrobots were imaged using a high-speed CCD camera (Basler
                    AG, Germany) paired with a Nikon Ti microscope equipped with a 100×
                    oil immersion lens. For data collection, the printed microrobots were
                    fixed on a glass slide and positioned on a piezo stage, enabling precise
                    ground truth trajectory generation along the z-axis. The microrobots
                    were moved across different poses on the piezo stage in either discrete
                    or continuous mode.
                    Live video recordings were captured and subsequently processed
                    offline. Following 2D position detection and estimation, each video was
                    cropped to a 256 × 256 pixel resolution for analysis.
                </div>
            </div>
        </div>

        <div id="footer">
            <p> &copy; 2024 <a href="https://www.intelligentroboticsacrossscales.com/">Multi-Scale Embodied Intelligence Lab, </a>
                <a href="https://www.imperial.ac.uk/">Imperial College London</a>, 
                <a href="mailto:d.zhang17@imperial.ac.uk">d.zhang17@imperial.ac.uk</a> &
                <a href="mailto:l.wei24@imperial.ac.uk">l.wei24@imperial.ac.uk</a> 
            </p>
        </div>
    </div>
</body>

<script>
    function scrollToSection(sectionId) {
    const section = document.getElementById(sectionId);
    if (section) {
        section.scrollIntoView({ behavior: 'smooth' });
    }
}
</script>

</html>